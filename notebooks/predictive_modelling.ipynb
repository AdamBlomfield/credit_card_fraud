{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "* Confusion matrix diagram for best model\n",
    "* Add explanation for why to use SMOTE, options of over and/or under sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T20:29:10.814203Z",
     "start_time": "2020-06-02T20:29:09.700663Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Preparation\n",
    "    # Train:Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model Tuning and Cross Validation\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier \n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier \n",
    "\n",
    "import itertools\n",
    "\n",
    "# # KNN\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn import metrics\n",
    "# from scipy.spatial import distance\n",
    "# # Logistic Regression\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "#     # Statsmodel\n",
    "# import statsmodels.api as sm\n",
    "# from patsy import dmatrices\n",
    "\n",
    "# # Random Forest\n",
    "# from sklearn.tree import DecisionTreeClassifier  # Decision Tree\n",
    "# from sklearn.ensemble import BaggingClassifier, RandomForestClassifier  #Bagging & Random Forest\n",
    "# from sklearn import tree\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "#     # Visuals for Random Forest\n",
    "# from sklearn.externals.six import StringIO\n",
    "# from IPython.display import Image\n",
    "# from sklearn.tree import export_graphviz\n",
    "\n",
    "# # SVC\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import classification_report, confusion_matrix , accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Cleaned Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T20:29:13.615373Z",
     "start_time": "2020-06-02T20:29:10.816135Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/cleaned_dataframe.gz', compression='gzip')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T20:29:17.045316Z",
     "start_time": "2020-06-02T20:29:13.617621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Scaled_Amount</th>\n",
       "      <th>Scaled_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>1.774718</td>\n",
       "      <td>-0.995290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.268530</td>\n",
       "      <td>-0.995290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>4.959811</td>\n",
       "      <td>-0.995279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Class  Scaled_Amount  Scaled_Time  \n",
       "0 -0.189115  0.133558 -0.021053      0       1.774718    -0.995290  \n",
       "1  0.125895 -0.008983  0.014724      0      -0.268530    -0.995290  \n",
       "2 -0.139097 -0.055353 -0.059752      0       4.959811    -0.995279  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = pd.read_csv('../data/processed/cleaned_dataframe_scaled.gz', compression='gzip')\n",
    "df_scaled.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train:Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T20:29:17.241961Z",
     "start_time": "2020-06-02T20:29:17.047672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples in each training set:\t198608\n",
      "No. of samples in each test set:\t85118\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Class'], axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=1)\n",
    "\n",
    "print(\"No. of samples in each training set:\\t{}\".format(X_train.shape[0]))\n",
    "print(\"No. of samples in each test set:\\t{}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to stratify as we want to keep the distribution of classes the same in the training set as the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T20:29:17.582115Z",
     "start_time": "2020-06-02T20:29:17.243543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples in each training set:\t198608\n",
      "No. of samples in each test set:\t85118\n"
     ]
    }
   ],
   "source": [
    "X_sc = df_scaled.drop(['Class'], axis=1)\n",
    "y_sc = df_scaled['Class']\n",
    "\n",
    "X_train_sc, X_test_sc, y_train_sc, y_test_sc = train_test_split(X_sc, y_sc,\n",
    "                                                                test_size=0.3,\n",
    "                                                                stratify=y_sc,\n",
    "                                                                random_state=1)\n",
    "\n",
    "\n",
    "print(\"No. of samples in each training set:\\t{}\".format(X_train.shape[0]))\n",
    "print(\"No. of samples in each test set:\\t{}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model & Model Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Baseline Model is if we decided to predict onl the majority Class (non-fraud).  Due to the high imbalance of the dataset, our baseline model will return a very high accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T20:38:44.818344Z",
     "start_time": "2020-06-02T20:38:44.788025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Baseline Model, where we say all transactions are not fraud, gives us an accuracy of 99.83%\n"
     ]
    }
   ],
   "source": [
    "num_of_transactions = len(df)\n",
    "num_of_frauds = len(df[df['Class']==0])\n",
    "accuracy = round((num_of_frauds/num_of_transactions)*100, 2)\n",
    "explanation = 'A Baseline Model, where we say all transactions are not fraud, gives us an accuracy of'\n",
    "print(explanation, '{}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good model will catch as many frauds as possible while minimizing the number of transactions flagged as fraud that are actually legitimate.\n",
    "\n",
    "If we want to know how well a model predicts the minority class (fraud), F1 is the most useful metric. F1 is a weighted average of *Precision* and *Recall*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision \n",
    "\\begin{equation*}\n",
    "\\frac{True Positives}{True Positives + False Positives}\n",
    "\\end{equation*}\n",
    "\n",
    "### Recall\n",
    "\\begin{equation*}\n",
    "\\frac{True Positives}{True Positives + False Negatives}\n",
    "\\end{equation*}\n",
    "\n",
    "### F1 Score\n",
    "\\begin{equation*}\n",
    "2*\\frac{Precision * Recall}{Precision + Recall}\n",
    "\\end{equation*}\n",
    "\n",
    "We also looked at Precision-Recall curves to get a sense of how well the model captures true positives. A PR curve plots the Precision and Recall scores across different thresholds for a positive identification. This helps us to see whether a model captures true positives while minimizing false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques Used\n",
    "\n",
    "Here are the techniques we used to get the best model:\n",
    "\n",
    "* Balancing the data with over-sampling \n",
    "\n",
    "> We used the imblearn library's Synthetic Minority Oversampling Technique (SMOTE) to generate additional instances of fraud between the existing ones and their k-nearest neighbors. \n",
    "\n",
    "* A Random Forest classifier\n",
    "\n",
    "> A Random Forest classifier uses an ensemble of decision trees that are trained using different portions of the data and different combinations of features. The forests predicts based on what the majority of trees in the forest predict.   \n",
    "\n",
    "* Using class weights\n",
    "\n",
    "> Class weights ensure that there is a higher penalty for misclassifying instances of fraud. \n",
    "\n",
    "Before settling on these techniques, we compared three class-balancing methods using a number of candidate classifiers. Here is a summary of the resulting F1 scores:\n",
    "\n",
    "\n",
    "| Classifier           | Oversampled minority | Undersampled majority class | Mix of Both |\n",
    "|----------------------|----------------------|-----------------------------|-------------|\n",
    "|Random Forest         | .63                  | .14                         | .27         | \n",
    "|Logistic Regression   | .04                  | .03                         | .05         |\n",
    "|K-nearest Neighbors   | .27                  | .14                         | .06         |\n",
    "|Support Vector Machine| .06                  | .04                         | .09         |\n",
    "|Gradient Boosting.    | .30                  | .07                         | .14         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T20:30:51.934689Z",
     "start_time": "2020-06-02T20:30:51.069035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: \t0.9927\n",
      "Train Precision:\t0.1576\n",
      "Train Recall:\t\t0.7825\n",
      "Train F1:\t\t0.2624\n",
      "\n",
      "\n",
      "Test Accuracy:\t\t0.9925\n",
      "Test Precision:\t\t0.1406\n",
      "Test Recall:\t\t0.6831\n",
      "Test F1:\t\t0.2332\n"
     ]
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "\n",
    "smote = SMOTE(random_state=1)\n",
    "\n",
    "pipe = make_pipeline(smote, classifier)\n",
    "model = pipe.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# print scores  \n",
    "rounding = 4\n",
    "print('Train Accuracy: \\t{}'.format(str(round(metrics.accuracy_score(y_train, train_predictions), rounding))))\n",
    "print('Train Precision:\\t{}'.format(str(round(metrics.precision_score(y_train, train_predictions), rounding))))\n",
    "print('Train Recall:\\t\\t{}'.format(str(round(metrics.recall_score(y_train, train_predictions), rounding))))\n",
    "print('Train F1:\\t\\t{}'.format(str(round(metrics.f1_score(y_train, train_predictions), rounding))))\n",
    "print('\\n')\n",
    "print('Test Accuracy:\\t\\t{}'.format(str(round(metrics.accuracy_score(y_test, test_predictions), rounding))))\n",
    "print('Test Precision:\\t\\t{}'.format(str(round(metrics.precision_score(y_test, test_predictions), rounding))))\n",
    "print('Test Recall:\\t\\t{}'.format(str(round(metrics.recall_score(y_test, test_predictions), rounding))))\n",
    "print('Test F1:\\t\\t{}'.format(str(round(metrics.f1_score(y_test, test_predictions), rounding))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
