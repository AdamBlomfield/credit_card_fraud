{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL;DR**: \n",
    "This notebook compares 3 classificaiton models and 2 resampling techniques to find the highest F-1 score for identifying fraudulent transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>**Contents**</ins>:\n",
    "* [Library Imports](#Library-Imports)\n",
    "* [Data Import](#Data-Import)\n",
    "* [Modeling](#Modeling)\n",
    "    * [Baseline Model & Model Metrics](#Baseline-Model-&-Model-Metrics)\n",
    "    * [Gaussian Naive Bayes](#Gaussian-Naive-Bayes-(GNB))\n",
    "    * [Random Forest](#Random-Forest-(RF))\n",
    "    * [eXtreme Gradient Boosting (XGBoost)](#XGBoost-(XGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:29.259359Z",
     "start_time": "2020-10-01T23:06:24.078228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model Tuning and Cross Validation\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Model metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# # Classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:29.530579Z",
     "start_time": "2020-10-01T23:06:29.261089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import functions.py file\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from functions.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:29.535100Z",
     "start_time": "2020-10-01T23:06:29.532945Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:33.948468Z",
     "start_time": "2020-10-01T23:06:29.536931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Original Training Dataset\n",
    "X_train = pd.read_csv('../data/processed/x_train.gz', compression='gzip')\n",
    "y_train = pd.read_csv('../data/processed/y_train.gz', compression='gzip').values.ravel()\n",
    "# y_train.dropna(inplace=True)\n",
    "\n",
    "# Training Dataset resampled with SMOTE\n",
    "X_train_smote = pd.read_csv('../data/processed/x_train_smote.gz', compression='gzip')\n",
    "y_train_smote = pd.read_csv('../data/processed/y_train_smote.gz', compression='gzip').values.ravel()\n",
    "# y_train_smote.dropna(inplace=True)\n",
    "\n",
    "# Training Dataset resampled with Random Undersampling\n",
    "X_train_under = pd.read_csv('../data/processed/x_train_under.gz', compression='gzip')\n",
    "y_train_under = pd.read_csv('../data/processed/y_train_under.gz', compression='gzip').values.ravel()\n",
    "# y_train_under.dropna(inplace=True)\n",
    "\n",
    "# Training Dataset resampled with SMOTE and Random Undersampling\n",
    "X_train_smote_under = pd.read_csv('../data/processed/x_train_smote_under.gz', compression='gzip')\n",
    "y_train_smote_under = pd.read_csv('../data/processed/y_train_smote_under.gz', compression='gzip').values.ravel()\n",
    "# y_train_smote_under.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:34.773505Z",
     "start_time": "2020-10-01T23:06:33.950199Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('../data/processed/x_test.gz', compression='gzip')\n",
    "y_test = pd.read_csv('../data/processed/y_test.gz', compression='gzip').values.ravel()\n",
    "# y_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe to keep track of Scores & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:34.781930Z",
     "start_time": "2020-10-01T23:06:34.775364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build scores dataframes for comparison\n",
    "scores_columns = ['Original', 'SMOTE', 'Undersampled', 'SMOTE & Undersampled']\n",
    "# F1 scores\n",
    "f1_scores_df = pd.DataFrame(columns=scores_columns)\n",
    "# Recall scores\n",
    "recall_scores_df = pd.DataFrame(columns=scores_columns)\n",
    "# Predictions\n",
    "preds_df = pd.DataFrame()\n",
    "# Prediction Probabilities\n",
    "preds_proba_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T18:54:53.172839Z",
     "start_time": "2020-08-06T18:54:53.167723Z"
    }
   },
   "source": [
    "* The function we use makes use of sklearn's GridSearchCV function.  \n",
    "* Grid Search is an **exhaustive search** using the parameter values that we provide, in order **to optimize our model**.\n",
    "    * Not every possible parameter combination is tested, so we can not guarantee a globally optimal combination of parameter values.\n",
    "    * The model will ony be as good as the possible combinations of parameters that we provide.\n",
    "    * the more parameter combinations we input, the longer the model will take to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model & Model Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high imbalance in our dataset, it is very easy to obtain a high accuracy by simply classifying every observation as the majority class (non-fraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:34.804805Z",
     "start_time": "2020-10-01T23:06:34.783640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 0.99827\n"
     ]
    }
   ],
   "source": [
    "# Baseline model that all predictions are majority class\n",
    "y_pred_base = [0] * len(y_test)\n",
    "\n",
    "# Calculate Accuracy of Baseline Model\n",
    "acc_base = round(accuracy_score(y_test, y_pred_base), 5)\n",
    "print('Baseline Model Accuracy: {}'.format(acc_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model with this level of accuracy will initially seem highly successful, but once we realise it has not caught a single fraudulent transaction, we then realise that **we need a different performance metric to accuracy**.  \n",
    "   * 99.83% Accuracy can still be used as a starting point, or baseline, from which more sophisticated models can improve upon.\n",
    "\n",
    "Alternative metrics to Accuracy include:  \n",
    "\n",
    "### Precision \n",
    "* Out of all the frauds our model predicted, what proportion were actually frauds?\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{True Positives}{True Positives + False Positives}\n",
    "\\end{equation*}\n",
    "\n",
    "### Recall\n",
    "* Out of all the actual frauds, what proportion did our model detect?\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{True Positives}{True Positives + False Negatives}\n",
    "\\end{equation*}\n",
    "\n",
    "### F1 Score\n",
    "* Considers both Precision and Recall.  Can be interpreted as a weighted average of the two (harmonic mean)\n",
    "\n",
    "\\begin{equation*}\n",
    "2*\\frac{Precision * Recall}{Precision + Recall}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "**To avoid confusion in this project, True Positive refers to predicting fraud and it is a fraud.**\n",
    "\n",
    "When seeking to classify fraudulent transactions, the **cost for misclassifying frauds** (False Negative) **is greater than misclassifying a legitimate transaction** (False Positive).\n",
    "   * An undetected fraud could potentially cost the customer and bank a lot of money.\n",
    "   * A legitimate transaction, flagged as fraud, may cause inconvenience for the customer and requires a team within the bank to authorize the transaction.\n",
    "   \n",
    "For our model we will **focus on the F1 Score** and place more emphasis on a high **Recall** rather than Precision.\n",
    "* The F1 Score will be the most useful metric as it is includes Recall and Precision.\n",
    "* Focusing on Recall as well, reflects the fact that classifying frauds (class 1) is more important than classifying legitimate transactions (class 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:35.224534Z",
     "start_time": "2020-10-01T23:06:34.808134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "TN: 85295 FP: 0 FN: 148 TP: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for baseline model\n",
    "custom_confusion_matrix(y_test, y_pred_base, 'Baseline', 'not resampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:35.324907Z",
     "start_time": "2020-10-01T23:06:35.226872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model F1 Score: 0.0\n",
      "Baseline Mode Recall Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 Score of Baseline Model\n",
    "f1_base = round(f1_score(y_test, y_pred_base), 8)\n",
    "print('Baseline Model F1 Score: {}'.format(f1_base))\n",
    "\n",
    "# Calculate Recall of Baseline Model\n",
    "recall_base = round(recall_score(y_test, y_pred_base), 8)\n",
    "print('Baseline Mode Recall Score: {}'.format(recall_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Model's F1 Score and Recall are 0 as the baseline model has a True Positive of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:35.331615Z",
     "start_time": "2020-10-01T23:06:35.326374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update F1 Scores table\n",
    "f1_scores_df.loc['Baseline'] = [f1_base] * 4\n",
    "\n",
    "# Update Recall Scores table\n",
    "recall_scores_df.loc['Baseline'] = [recall_base] * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes (GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>Classifier information</strong></summary>\n",
    "    <br>\n",
    "\n",
    "* This classification method is based on Bayes' Theorem and although it is one of the earliest classification techniques, it is still extremey powerful.  \n",
    "* The classifier is essentially asking, \"given the Amount = X, the V1 = Y, V2 = Z etc...what is the most likely Class for this observation?\"\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:35.335364Z",
     "start_time": "2020-10-01T23:06:35.333216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate Gaussian Naive Bayes Classifer\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "# Build Parameter Grid\n",
    "param_grid_gnb = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:36.789058Z",
     "start_time": "2020-10-01T23:06:35.336830Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB - Original Dataset:\n",
      "Best Test Data F1 score: \t0.11738\n",
      "Best Test Data Recall score: \t0.86486\n",
      "\n",
      "GNB - SMOTE Dataset:\n",
      "Best Test Data F1 score: \t0.11121\n",
      "Best Test Data Recall score: \t0.86486\n",
      "\n",
      "GNB - Random Undersampled Dataset:\n",
      "Best Test Data F1 score: \t0.12187\n",
      "Best Test Data Recall score: \t0.87162\n",
      "\n",
      "GNB - SMOTE and Random Undersampled Dataset:\n",
      "Best Test Data F1 score: \t0.10441\n",
      "Best Test Data Recall score: \t0.87162\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Bayes with Original training data\n",
    "print('GNB - Original Dataset:')\n",
    "f1_gnb_original, recall_gnb_original, y_pred_gnb_original, y_pred_proba_gnb_original = best_model_score(clf_gnb, param_grid_gnb, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Gaussian Bayes with SMOTE training data\n",
    "print('\\nGNB - SMOTE Dataset:')\n",
    "f1_gnb_smote, recall_gnb_smote, y_pred_gnb_smote, y_pred_proba_gnb_smote = best_model_score(clf_gnb, param_grid_gnb, X_train_smote, y_train_smote, X_test, y_test)\n",
    "\n",
    "# Gaussian Bayes with Random Undersampled training data\n",
    "print('\\nGNB - Random Undersampled Dataset:')\n",
    "f1_gnb_under, recall_gnb_under, y_pred_gnb_under, y_pred_proba_gnb_under = best_model_score(clf_gnb, param_grid_gnb, X_train_under, y_train_under, X_test, y_test)\n",
    "\n",
    "# Gaussian Bayes with SMOTE and Random Undersampled training data\n",
    "print('\\nGNB - SMOTE and Random Undersampled Dataset:')\n",
    "f1_gnb_smote_under, recall_gnb_smote_under, y_pred_gnb_smote_under, y_pred_proba_gnb_smote_under = best_model_score(clf_gnb, param_grid_gnb, X_train_smote_under, y_train_smote_under, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:36.867469Z",
     "start_time": "2020-10-01T23:06:36.791200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update F1 Scores table\n",
    "f1_scores_df.loc['Gaussian Naive Bayes'] = [f1_gnb_original, f1_gnb_smote, f1_gnb_under, f1_gnb_smote_under]\n",
    "\n",
    "# Update Recall Scores table\n",
    "recall_scores_df.loc['Gaussian Naive Bayes'] = [recall_gnb_original, recall_gnb_smote, recall_gnb_under, recall_gnb_smote_under]\n",
    "\n",
    "# Update Predictions table\n",
    "preds = {'y_pred_gnb_original': y_pred_gnb_original, 'y_pred_gnb_smote':y_pred_gnb_smote, 'y_pred_gnb_under':y_pred_gnb_under, 'y_pred_gnb_smote_under':y_pred_gnb_smote_under}\n",
    "gnb_preds_df = pd.DataFrame(preds)\n",
    "preds_df = pd.concat([preds_df, gnb_preds_df], axis=1, sort=False)\n",
    "\n",
    "# Update Predictions Probability table\n",
    "preds_proba = {'y_pred_proba_gnb_original': list(y_pred_proba_gnb_original), 'y_pred_proba_gnb_smote':list(y_pred_proba_gnb_smote), 'y_pred_proba_gnb_under':list(y_pred_proba_gnb_under), 'y_pred_proba_gnb_smote_under':list(y_pred_proba_gnb_smote_under)}\n",
    "gnb_preds_proba_df = pd.DataFrame(preds_proba)\n",
    "preds_proba_df = pd.concat([preds_proba_df, gnb_preds_proba_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>Classifier information</strong></summary>\n",
    "    <br>\n",
    "\n",
    "* A Random Forest classifier uses an ensemble of decision trees that are trained using different portions of the data and different combinations of features. The forests predicts based on what the majority of trees in the forest predict.\n",
    "    </details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:06:36.872222Z",
     "start_time": "2020-10-01T23:06:36.868978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate Random Forest Classifer\n",
    "clf_rf = RandomForestClassifier(criterion='gini', \n",
    "                                class_weight={0: 1, 1: 2}, \n",
    "                                n_jobs=-1, \n",
    "                                random_state=random_seed)\n",
    "\n",
    "# Build Parameter Grid\n",
    "param_grid_rf = {'n_estimators': [50], \n",
    "                   'max_depth': [30, None], \n",
    "                 'min_samples_leaf': [1,3], \n",
    "                   'min_samples_split': [3,4]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>Parameter Tuning Guide<strong></summary>\n",
    "    <br>\n",
    "\n",
    "*criterion*\n",
    "* The function to measure the quality of a split.\n",
    "* \"Gini\" (Gini impurity) will often produce the same results as \"Entropy\" (information gain) but Entropy is more computaionally expensive.\n",
    "\n",
    "*class_weight*\n",
    "* Weights associated with classes in the form {class_label: weight}.\n",
    "* We want our model to focus more on catching frauds, than catching legitimate transactions.\n",
    "\n",
    "*n_estimators*\n",
    "* Increasing this will improve the model as predictions will be based off a larger number of \"votes\", but it will also make it more computationally expensive\n",
    "\n",
    "*max_depth*\n",
    "* The max depth of the trees.  \n",
    "* Too large and we risk overfitting the data.\n",
    "* Too small and we prevent the trees being able to explain some of the variation in the data.\n",
    "\n",
    "*min_samples_leaf*\n",
    "* Minimum number of samples required to be at a leaf node.  \n",
    "* Too large will risk the trees not splitting enough to capture sufficient variation in the data\n",
    "\n",
    "*min_samples_split*\n",
    "* Minimum number of samples required to split an internal node\n",
    "* Too large will cause under-fitting as the trees won't be able to split enough to achieve node purity\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:14:25.811447Z",
     "start_time": "2020-10-01T23:06:36.873610Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Original Dataset:\n",
      "Best Test Data F1 score: \t0.88571\n",
      "Best Test Data Recall score: \t0.83784\n",
      "\n",
      "Optimal parameters:\n",
      "\tmax_depth: 30\n",
      "\tmin_samples_leaf: 1\n",
      "\tmin_samples_split: 3\n",
      "\tn_estimators: 50\n",
      "\n",
      "RF - SMOTE Dataset:\n",
      "Best Test Data F1 score: \t0.87973\n",
      "Best Test Data Recall score: \t0.86486\n",
      "\n",
      "Optimal parameters:\n",
      "\tmax_depth: None\n",
      "\tmin_samples_leaf: 1\n",
      "\tmin_samples_split: 3\n",
      "\tn_estimators: 50\n",
      "\n",
      "RF - Random Undersampled Dataset:\n",
      "Best Test Data F1 score: \t0.22259\n",
      "Best Test Data Recall score: \t0.89865\n",
      "\n",
      "Optimal parameters:\n",
      "\tmax_depth: 30\n",
      "\tmin_samples_leaf: 3\n",
      "\tmin_samples_split: 3\n",
      "\tn_estimators: 50\n",
      "\n",
      "RF - SMOTE and Random Undersampled Dataset:\n",
      "Best Test Data F1 score: \t0.82243\n",
      "Best Test Data Recall score: \t0.89189\n",
      "\n",
      "Optimal parameters:\n",
      "\tmax_depth: 30\n",
      "\tmin_samples_leaf: 1\n",
      "\tmin_samples_split: 4\n",
      "\tn_estimators: 50\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Original training data\n",
    "print('RF - Original Dataset:')\n",
    "f1_rf_original, recall_rf_original, y_pred_rf_original, y_pred_proba_rf_original = best_model_score(clf_rf, param_grid_rf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Random Forest with SMOTE training data\n",
    "print('\\nRF - SMOTE Dataset:')\n",
    "f1_rf_smote, recall_rf_smote, y_pred_rf_smote, y_pred_proba_rf_smote = best_model_score(clf_rf, param_grid_rf, X_train_smote, y_train_smote, X_test, y_test)\n",
    "\n",
    "# Random Forest with Random Undersampled training data\n",
    "print('\\nRF - Random Undersampled Dataset:')\n",
    "f1_rf_under, recall_rf_under, y_pred_rf_under, y_pred_proba_rf_under = best_model_score(clf_rf, param_grid_rf, X_train_under, y_train_under, X_test, y_test)\n",
    "\n",
    "# Random Forest with SMOTE and Random Undersampled training data\n",
    "print('\\nRF - SMOTE and Random Undersampled Dataset:')\n",
    "f1_rf_smote_under, recall_rf_smote_under, y_pred_rf_smote_under, y_pred_proba_rf_smote_under = best_model_score(clf_rf, param_grid_rf, X_train_smote_under, y_train_smote_under, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:14:25.924418Z",
     "start_time": "2020-10-01T23:14:25.813831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update F1 Scores table\n",
    "f1_scores_df.loc['Random Forest'] = [f1_rf_original, f1_rf_smote, f1_rf_under, f1_rf_smote_under]\n",
    "\n",
    "# Update Recall Scores table\n",
    "recall_scores_df.loc['Random Forest'] = [recall_rf_original, recall_rf_smote, recall_rf_under, recall_rf_smote_under]\n",
    "\n",
    "# Update Predictions table\n",
    "preds = {'y_pred_rf_original': y_pred_rf_original, 'y_pred_rf_smote':y_pred_rf_smote, 'y_pred_rf_under':y_pred_rf_under, 'y_pred_rf_smote_under':y_pred_rf_smote_under}\n",
    "rf_preds_df = pd.DataFrame(preds)\n",
    "preds_df = preds_df.join(rf_preds_df)\n",
    "\n",
    "# Update Predictions Probability table\n",
    "preds_proba = {'y_pred_proba_rf_original': list(y_pred_proba_rf_original), 'y_pred_proba_rf_smote': list(y_pred_proba_rf_smote), 'y_pred_proba_rf_under':list(y_pred_proba_rf_under), 'y_pred_proba_rf_smote_under': list(y_pred_proba_rf_smote_under)}\n",
    "rf_preds_proba_df = pd.DataFrame(preds_proba)\n",
    "preds_proba_df = pd.concat([preds_proba_df, rf_preds_proba_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost (XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>Classifier information</strong></summary>\n",
    "    <br>\n",
    "\n",
    "eXtreme Gradient Boosting (XGBoost) is a form of gradient-boosted decision trees. \n",
    "\n",
    "In a standard ensemble method such as Random Forest, models are trained in isolation so all of the models might make the same mistakes.\n",
    "\n",
    "Gradient Boosting methods, such as XGBoost, trains the Trees in succession.  \n",
    "* Each new Tree is trained to correct the errors made by the previous Trees.  \n",
    "* Trees are added sequentially until either no further improvements can be made or a specified number of trees is reached.\n",
    "* Note that Boosted classifiers do not necessarily have to be tree-based, though often are.\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:14:25.975341Z",
     "start_time": "2020-10-01T23:14:25.971286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate XGBClassifier\n",
    "scale_pos_weight = 10\n",
    "clf_xgb = XGBClassifier(booster='gbtree', tree_method='hist', scale_pos_weight=scale_pos_weight, verbosity=0,\n",
    "                    seed=random_seed\n",
    "                   )\n",
    "\n",
    "# Build Parameter Grid\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.2, 0.3],\n",
    "    'objective': ['binary:hinge'],\n",
    "    'max_depth': [30, 50],\n",
    "    'min_child_weight': [3],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>Parameter Tuning Guide<strong></summary>\n",
    "    <br>\n",
    "\n",
    "*booster*\n",
    "* \"gbtree\" uses tree based models\n",
    "\n",
    "*tree_method*\n",
    "* \"hist\" allows for faster computation\n",
    "\n",
    "*scale_pos_weight\n",
    "* Ratio of legitimate transactions to frauds.\n",
    "* This helps the model deal with imbalanced datasets.\n",
    "\n",
    "*learning_rate*\n",
    "* This is the step size shrinkage used in each update.  It prevents overfitting\n",
    "\n",
    "*objective*\n",
    "* \"binary:hinge\" is for binary classification.  A prediction of 0 or 1 is output, rather than producing probabilities\n",
    "\n",
    "*max_depth*\n",
    "* Max number of nodes from root to furthest leaf.\n",
    "* Too large and splits will eventually become less relevant and overfitting will occur.\n",
    "* Too small and we won't be able to model more complex relationships in the data.\n",
    "\n",
    "*min_child_weight*\n",
    "* Min weight or number of samples needed to create a new node.\n",
    "* Too large and our model will not be able to create children to correspond to \n",
    "* Too small and we risk overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:14:58.680386Z",
     "start_time": "2020-10-01T23:14:25.977337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB - Original Dataset:\n",
      "Best Test Data F1 score: \t0.86525\n",
      "Best Test Data Recall score: \t0.82432\n",
      "\n",
      "Optimal parameters:\n",
      "\tlearning_rate: 0.2\n",
      "\tmax_depth: 30\n",
      "\tmin_child_weight: 3\n",
      "\tobjective: binary:hinge\n",
      "\n",
      "XGB - SMOTE Dataset:\n",
      "Best Test Data F1 score: \t0.86195\n",
      "Best Test Data Recall score: \t0.86486\n",
      "\n",
      "Optimal parameters:\n",
      "\tlearning_rate: 0.2\n",
      "\tmax_depth: 30\n",
      "\tmin_child_weight: 3\n",
      "\tobjective: binary:hinge\n",
      "\n",
      "XGB - Random Undersampled Dataset:\n",
      "Best Test Data F1 score: \t0.11703\n",
      "Best Test Data Recall score: \t0.89865\n",
      "\n",
      "Optimal parameters:\n",
      "\tlearning_rate: 0.2\n",
      "\tmax_depth: 30\n",
      "\tmin_child_weight: 3\n",
      "\tobjective: binary:hinge\n",
      "\n",
      "XGB - SMOTE and Random Undersampled Dataset:\n",
      "Best Test Data F1 score: \t0.6514\n",
      "Best Test Data Recall score: \t0.86486\n",
      "\n",
      "Optimal parameters:\n",
      "\tlearning_rate: 0.2\n",
      "\tmax_depth: 30\n",
      "\tmin_child_weight: 3\n",
      "\tobjective: binary:hinge\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with Original training data\n",
    "print('XGB - Original Dataset:')\n",
    "# Class weights\n",
    "(y_class, y_train_counts) = np.unique(y_train, return_counts=True) # Value counts for Class 0 and 1\n",
    "clf_xgb.scale_pos_weight = y_train_counts[0] / y_train_counts[1] # Ratio of Class 1: Class 0\n",
    "\n",
    "# Fit model\n",
    "f1_xgb_original, recall_xgb_original, y_pred_xgb_original, y_pred_proba_xgb_original = best_model_score(clf_xgb, \n",
    "                                                                                                        param_grid_xgb, \n",
    "                                                                                                        X_train, \n",
    "                                                                                                        y_train, \n",
    "                                                                                                        X_test, \n",
    "                                                                                                        y_test)\n",
    "\n",
    "\n",
    "# XGBoost with SMOTE training data\n",
    "print('\\nXGB - SMOTE Dataset:')\n",
    "# Class weights\n",
    "(y_class, y_train_smote_counts) = np.unique(y_train_smote, return_counts=True)\n",
    "clf_xgb.scale_pos_weight = y_train_smote_counts[0] / y_train_smote_counts[1]\n",
    "\n",
    "# Fit model\n",
    "f1_xgb_smote, recall_xgb_smote, y_pred_xgb_smote, y_pred_proba_xgb_smote = best_model_score(clf_xgb, \n",
    "                                                                                            param_grid_xgb, \n",
    "                                                                                            X_train_smote, \n",
    "                                                                                            y_train_smote, \n",
    "                                                                                            X_test, \n",
    "                                                                                            y_test)\n",
    "\n",
    "# XGBoost with Random Undersampled training data\n",
    "print('\\nXGB - Random Undersampled Dataset:')\n",
    "# Class weights\n",
    "(y_class, y_train_under_counts) = np.unique(y_train_under, return_counts=True)\n",
    "clf_xgb.scale_pos_weight = y_train_under_counts[0] / y_train_under_counts[1]\n",
    "\n",
    "# Fit model\n",
    "f1_xgb_under, recall_xgb_under, y_pred_xgb_under, y_pred_proba_xgb_under = best_model_score(clf_xgb, \n",
    "                                                                                            param_grid_xgb, \n",
    "                                                                                            X_train_under, \n",
    "                                                                                            y_train_under, \n",
    "                                                                                            X_test, \n",
    "                                                                                            y_test)\n",
    "# XGBoost with SMOTE and Random Undersampled training data\n",
    "print('\\nXGB - SMOTE and Random Undersampled Dataset:')\n",
    "# Class weights\n",
    "(y_class, y_train_smote_under_counts) = np.unique(y_train_smote_under, return_counts=True)\n",
    "clf_xgb.scale_pos_weight = y_train_smote_under_counts[0] / y_train_smote_under_counts[1]\n",
    "\n",
    "# Fit model\n",
    "f1_xgb_smote_under, recall_xgb_smote_under, y_pred_xgb_smote_under, y_pred_proba_xgb_smote_under = best_model_score(clf_xgb, \n",
    "                                                                                                                    param_grid_xgb, \n",
    "                                                                                                                    X_train_smote_under, \n",
    "                                                                                                                    y_train_smote_under, \n",
    "                                                                                                                    X_test, \n",
    "                                                                                                                    y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T23:14:58.829662Z",
     "start_time": "2020-10-01T23:14:58.682767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update F1 Scores table\n",
    "f1_scores_df.loc['XGBoost'] = [f1_xgb_original, f1_xgb_smote, f1_xgb_under, f1_xgb_smote_under]\n",
    "\n",
    "# Update Recall Scores table\n",
    "recall_scores_df.loc['XGBoost'] = [recall_xgb_original, recall_xgb_smote, recall_xgb_under, recall_xgb_smote_under]\n",
    "\n",
    "# Update Predictions table\n",
    "preds = {'y_pred_xgb_original': y_pred_xgb_original, 'y_pred_xgb_smote':y_pred_xgb_smote, 'y_pred_xgb_under':y_pred_xgb_under, 'y_pred_xgb_smote_under':y_pred_xgb_smote_under}\n",
    "xgb_preds_df = pd.DataFrame(preds)\n",
    "preds_df = preds_df.join(xgb_preds_df)\n",
    "\n",
    "# Update Predictions Probability table\n",
    "preds_proba = {'y_pred_proba_xgb_original': list(y_pred_proba_xgb_original), 'y_pred_proba_xgb_smote': list(y_pred_proba_xgb_smote), 'y_pred_proba_xgb_under': list(y_pred_proba_xgb_under), 'y_pred_proba_xgb_smote_under': list(y_pred_proba_xgb_smote_under)}\n",
    "xgb_preds_proba_df = pd.DataFrame(preds_proba)\n",
    "preds_proba_df = pd.concat([preds_proba_df, xgb_preds_proba_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T00:09:14.972549Z",
     "start_time": "2020-10-02T00:09:10.564457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save F1 Scores Table\n",
    "f1_scores_df.to_csv('../data/processed/f1_scores')\n",
    "\n",
    "# Save F1 Scores Table\n",
    "recall_scores_df.to_csv('../data/processed/recall_scores')\n",
    "\n",
    "# Predictions Table\n",
    "preds_df.to_csv('../data/processed/predictions')\n",
    "\n",
    "# # Prediction Probability Table\n",
    "preds_proba_df.to_pickle('../data/processed/predictions_probabilities.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
